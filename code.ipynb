{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b39192e5-bae1-4048-967c-dfd6e7d4f9da",
   "metadata": {},
   "source": [
    "Trupti Shriyan                                                                                                                                1002223250\n",
    "Programming Assignment                                                                                                                       Data Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3763fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary functions\n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29318031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up processing functions\n",
    "stop_words_in_text = set(stopwords.words('english'))\n",
    "stemmer_text = PorterStemmer()\n",
    "tokenizer_text = RegexpTokenizer(r'[a-zA-Z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba7237c4-86ba-4d37-ad29-17713b6351c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and preprocessing the documents\n",
    "def load_documents(directory_path):\n",
    "    docs = []\n",
    "    files = []  # To track filenames for reference\n",
    "    for file_name in os.listdir(root_path):\n",
    "        if file_name.endswith('.txt'):\n",
    "            file_path = os.path.join(root_path, file_name)\n",
    "            with open(file_path, 'r', encoding='windows-1252') as file:\n",
    "                doc = file.read().lower()\n",
    "            tokens = tokenizer_text.tokenize(doc)\n",
    "            tokens = [token for token in tokens if token not in stop_words_in_text]\n",
    "            tokens = [stemmer_text.stem(token) for token in tokens]\n",
    "            docs.append(tokens)\n",
    "            files.append(file_name)\n",
    "    return docs, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eedb9a0-c40d-4ae9-ac58-b34f9a4a3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifying the path where my acutal data is present\n",
    "root_path = 'US_Inaugural_Addresses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "589e5a83-c0b4-4885-8de7-4fe8cb2699bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded and preprocessed.\n"
     ]
    }
   ],
   "source": [
    "docs, files = load_documents(root_path)\n",
    "print(\"Documents loaded and preprocessed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e374e25-04b9-4995-9d8b-fe41a42f7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUilding the Term frequency - Inverse Document Frequency model\n",
    "def build_tfidf(docs):\n",
    "    N = len(docs)\n",
    "    document_frequency = Counter()\n",
    "    for tokens in docs:\n",
    "        unique_tokens = set(tokens)\n",
    "        for token in unique_tokens:\n",
    "            document_frequency[token] += 1\n",
    "\n",
    "    tfidf_vectors = []\n",
    "    for tokens in docs:\n",
    "        tf = Counter(tokens)\n",
    "        tfidf = {}\n",
    "        document_length = 0\n",
    "        for token, count in tf.items():\n",
    "            if token in document_frequency:\n",
    "                tf_value = 1 + math.log10(count)\n",
    "                idf_value = math.log10(N / document_frequency[token])\n",
    "                tfidf[token] = tf_value * idf_value\n",
    "                document_length += tfidf[token] ** 2\n",
    "\n",
    "        document_length = math.sqrt(document_length)\n",
    "        for token in tfidf:\n",
    "            tfidf[token] /= document_length\n",
    "        tfidf_vectors.append(tfidf)\n",
    "    return tfidf_vectors, document_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d20457d0-a1ae-4cbd-b6ca-75692d27cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF model built.\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectors, document_frequency = build_tfidf(docs)\n",
    "print(\"TF-IDF model built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5838aeb-8807-402c-bfd1-125abfe18c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Vector Calculation \n",
    "def calculate_query_vector(query):\n",
    "    tokens = tokenizer_text.tokenize(query.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words_in_text]\n",
    "    stemmed_tokens = [stemmer_text.stem(token) for token in filtered_tokens]\n",
    "    tf_query = Counter(stemmed_tokens)\n",
    "    query_vector = {}\n",
    "    for token, count in tf_query.items():\n",
    "        if token in document_frequency:\n",
    "            tf_value = 1 + math.log10(count)\n",
    "            idf_value = math.log10(len(docs) / document_frequency[token])\n",
    "            query_vector[token] = tf_value * idf_value\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73002c83-9e19-4b9a-997a-0283bcf73b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Cosine Similarity function\n",
    "def cosine_similarity(vector_1, vector_2):\n",
    "    intersection = set(vector_1.keys()) & set(vector_2.keys())\n",
    "    numerator = sum([vector_1[x] * vector_2[x] for x in intersection])\n",
    "    sum_1 = sum([value ** 2 for value in vector_1.values()])\n",
    "    sum_2 = sum([value ** 2 for value in vector_2.values()])\n",
    "    denominator = math.sqrt(sum_1) * math.sqrt(sum_2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ad1ea2e-d4f3-4eb0-910f-f55e57eee94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getidf(token):\n",
    "    token = stemmer_text.stem(token)\n",
    "    return math.log10(len(docs) / document_frequency.get(token, len(docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2537bba1-2b93-4819-8d02-7fbb736ae271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getweight(file_name, token):\n",
    "    token = stemmer_text.stem(token)\n",
    "    document_index = files.index(file_name)  # Using files list to get index\n",
    "    return tfidf_vectors[document_index].get(token, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dec9079-d07b-42af-87b7-1bb058e5fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(query_string):\n",
    "    query_vector = calculate_query_vector(query_string)\n",
    "    similarities = [(files[i], cosine_similarity(query_vector, document_vector)) for i, document_vector in enumerate(tfidf_vectors)]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[0] if similarities else (\"None\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "771ab063-5cde-4381-af9e-b5835011c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most relevant document: ('22_grant_1873.txt', 0.04422464468088289)\n"
     ]
    }
   ],
   "source": [
    "# Query the system\n",
    "results = query(\"We stand to-day with the Constitution\")\n",
    "print(f\"The most relevant document: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80dbf9f0-34c0-4bf7-a680-26f478c1ace5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875061263392\n",
      "0.115393418702\n",
      "1.176091259056\n",
      "0.045757490561\n",
      "0.029963223377\n",
      "--------------\n",
      "0.005140064841\n",
      "0.019316338877\n",
      "0.095677997843\n",
      "0.130886844655\n",
      "0.005091152688\n",
      "--------------\n",
      "(02_washington_1793.txt, 0.028040582186)\n",
      "(16_taylor_1849.txt, 0.016937704621)\n",
      "(11_jackson_1829.txt, 0.005111777487)\n",
      "(02_washington_1793.txt, 0.007771588100)\n",
      "(21_grant_1869.txt, 0.013452928185)\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "print(\"%.12f\" % getidf('british'))\n",
    "print(\"%.12f\" % getidf('union'))\n",
    "print(\"%.12f\" % getidf('dollar'))\n",
    "print(\"%.12f\" % getidf('constitution'))\n",
    "print(\"%.12f\" % getidf('power'))\n",
    "print(\"--------------\")\n",
    "print(\"%.12f\" % getweight('19_lincoln_1861.txt','states'))\n",
    "print(\"%.12f\" % getweight('07_madison_1813.txt','war'))\n",
    "print(\"%.12f\" % getweight('05_jefferson_1805.txt','false'))\n",
    "print(\"%.12f\" % getweight('22_grant_1873.txt','proposition'))\n",
    "print(\"%.12f\" % getweight('16_taylor_1849.txt','duties'))\n",
    "print(\"--------------\")\n",
    "print(\"(%s, %.12f)\" % query(\"executive power\"))\n",
    "print(\"(%s, %.12f)\" % query(\"foreign government\"))\n",
    "print(\"(%s, %.12f)\" % query(\"public rights\"))\n",
    "print(\"(%s, %.12f)\" % query(\"people government\"))\n",
    "print(\"(%s, %.12f)\" % query(\"states laws\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2b8e2-8d1d-495c-9677-d0c75a33a1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6889f-98eb-4981-8c3c-cd611a7d98fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e0ac0-07f1-4e09-9a32-6eedd52217fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f6bd4-6738-45ba-b1a5-194a8e58dd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
